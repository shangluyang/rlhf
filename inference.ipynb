{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b820c4c-538e-4a70-91cc-e2bf22e8b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "from transformers import BitsAndBytesConfig\n",
    "import wandb\n",
    "from dataset import build_dataset, collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416b4991-387a-4121-8024-02b978530994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f116d59-0a85-40e5-8a41-196a448fb04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at reference_model were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/gpt2-imdb\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained('gpt2-rlhf',  device_map=\"auto\")\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(pretrained_model)\n",
    "model.to(device)\n",
    "\n",
    "# Load a reference model with a value head\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained('reference_model')\n",
    "ref_model.to(device)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "sent_kwargs = {\n",
    "        \"return_all_scores\": True, \n",
    "        \"function_to_apply\": \"none\", \n",
    "        \"batch_size\": 16 \n",
    "}\n",
    "\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=\"lvwerra/gpt2-imdb\", \n",
    "    learning_rate=1.5e-5\n",
    ")\n",
    "\n",
    "dataset = build_dataset(config)\n",
    "\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"distilbert-imdb\", device=device)\n",
    "\n",
    "ppo_trainer = PPOTrainer(config, model, ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, dataset=dataset, \n",
    "                         data_collator=collator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4526d12a-dfbb-4fef-aab3-2dbf2ea58e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model, ppo_trainer, query_tensors, sample_size, device, generation_kwargs):\n",
    "    response_tensors_ref, response_tensors = [], []\n",
    "    for i in range(sample_size):\n",
    "        gen_len = output_length_sampler()\n",
    "        output = model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), **generation_kwargs).squeeze()[-gen_len:]\n",
    "        response_tensors_ref.append(output)\n",
    "        output = ppo_trainer.generate(torch.tensor(query_tensors[i]).to(device), **generation_kwargs).squeeze()[-gen_len:]\n",
    "        response_tensors.append(output)\n",
    "    return response_tensors_ref, response_tensors\n",
    "\n",
    "def decode_responses(tokenizer, response_tensors):\n",
    "    \"\"\"Decode the list of response tensors into human-readable text.\"\"\"\n",
    "    return [tokenizer.decode(tensor) for tensor in response_tensors]\n",
    "\n",
    "def reward_scores(sentiment_pipe, queries, responses, sent_kwargs):\n",
    "    \"\"\"Calculate sentiment scores for query-response pairs.\"\"\"\n",
    "    texts = [q + r for q, r in zip(queries, responses)]\n",
    "    return [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08aac1-5b9d-405f-a83e-e8bd48e9ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1156: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "sample_size = 40\n",
    "output_length_sampler = LengthSampler(4, 16)\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(sample_size)\n",
    "\n",
    "\n",
    "result_data = {\n",
    "    'query': df_batch['query'].tolist(),\n",
    "    'input_ids': df_batch['input_ids'].tolist()\n",
    "}\n",
    "\n",
    "\n",
    "# Generate responses before and after training\n",
    "response_tensors_ref, response_tensors = generate_responses(ref_model, ppo_trainer, result_data['input_ids'], sample_size, device, generation_kwargs)\n",
    "\n",
    "# Decode responses\n",
    "result_data['response (before)'] = decode_responses(tokenizer, response_tensors_ref)\n",
    "result_data['response (after)'] = decode_responses(tokenizer, response_tensors)\n",
    "\n",
    "# reward_scores\n",
    "result_data['rewards (before)'] = reward_scores(sentiment_pipe, result_data['query'], result_data['response (before)'], sent_kwargs)\n",
    "result_data['rewards (after)'] = reward_scores(sentiment_pipe, result_data['query'], result_data['response (after)'], sent_kwargs)\n",
    "\n",
    "# Store results in a DataFrame\n",
    "df_results = pd.DataFrame(result_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea0b69-1054-4a76-b9f3-706f0c1edf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average reward before RLHF is {round(df_results['rewards (before)'].mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25ef84-afca-4af7-9e82-d57875a5ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average reward after RLHF is {round(df_results['rewards (after)'].mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc1069a5-d766-44e2-9962-bcb94369125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('ppo_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca229754-0a73-4793-9721-90ec4f4eaae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
